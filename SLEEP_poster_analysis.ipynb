{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import sys\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as dates\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta, time, date\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import stats\n",
    "from statistics import median\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.transforms import offset_copy\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LifeAtCMU_Phase1/ and LifeAtCMU_Phase2/ folders contain the underlying Fitbit data. The first step is to save the combined sleep-steps into a single file for every participant. \n",
    "\n",
    "Here, we go from sleep_raw_data/ and steps_raw_data/ to sleep_steps_data/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPath(phase):\n",
    "    if phase == 'lac1':\n",
    "        path = 'LifeAtCMU_Phase1/'\n",
    "    elif phase == 'lac2':\n",
    "        path = 'LifeAtCMU_Phase2/'\n",
    "    else:\n",
    "        raise('Invalid phase argument')\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combines all raw sleep and raw steps \n",
    "# input: \"lac1\" or \"lac2\"\n",
    "def saveAllCombined(phase):\n",
    "\n",
    "    if phase == 'lac1':\n",
    "        TIME_INDEX = pd.date_range(start='1/16/2017',\n",
    "                                   end='5/15/2017',\n",
    "                                   freq='min')\n",
    "    elif phase == 'lac2':\n",
    "        TIME_INDEX = pd.date_range(start='1/16/2018',\n",
    "                                   end='5/15/2018',\n",
    "                                   freq='min')\n",
    "    else:\n",
    "        raise('Invalid phase argument')\n",
    "        \n",
    "    path = getPath(phase)\n",
    "       \n",
    "    sleep_dir = os.path.join(path,'sleep_raw_data/')\n",
    "    steps_dir = os.path.join(path,'steps_raw_data/')\n",
    "    combined_dir = os.path.join(path,'sleep_steps_data/')\n",
    "\n",
    "    sleep_files = os.listdir(sleep_dir)\n",
    "    steps_files = os.listdir(steps_dir)\n",
    "    both = list(set(sleep_files) & set(steps_files))\n",
    "\n",
    "    DATE_FORMAT = '%Y-%m-%d %H:%M:%S'\n",
    "    \n",
    "    for idx in tqdm(range(len(both))):\n",
    "\n",
    "        if os.path.exists(os.path.join(combined_dir, both[idx])):\n",
    "            continue\n",
    "        else:\n",
    "            try:\n",
    "                df_sleep = pd.read_csv(os.path.join(sleep_dir, both[idx]))\n",
    "                df_steps = pd.read_csv(os.path.join(steps_dir, both[idx]))\n",
    "\n",
    "                # Convert times to datetime objects\n",
    "                df_sleep['dt_typed'] = df_sleep['dateTime'].apply(lambda time: datetime.strptime(time,DATE_FORMAT).replace(second=0))\n",
    "                df_steps['dt_typed'] = df_steps['datetime'].apply(lambda time: datetime.strptime(time,DATE_FORMAT).replace(second=0))\n",
    "                df_sleep = df_sleep.rename(columns={'value' : 'sleep_value'})\n",
    "\n",
    "                df = pd.DataFrame(index=TIME_INDEX)\n",
    "                df = df.merge(df_sleep[['sleep_value','dt_typed']],how='left',left_index=True,right_on='dt_typed')\n",
    "                df = df.merge(df_steps[['steps','dt_typed']],how='left',left_on='dt_typed',right_on='dt_typed')\n",
    "                df = df.drop_duplicates(subset='dt_typed', keep='first')\n",
    "                df = df.set_index('dt_typed')\n",
    "\n",
    "                # lac1 only gives steps every 5 minutes, so we interpolate\n",
    "                if phase == 'lac1':\n",
    "                    df['steps'] = df['steps'].interpolate()\n",
    "\n",
    "                df.index.names = ['time']\n",
    "                df.sort_index(inplace=True)\n",
    "                df.to_csv(os.path.join(combined_dir, both[idx]))\n",
    "            except:\n",
    "                print(both[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saveAllCombined('lac1')\n",
    "# saveAllCombined('lac2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have all the combined sleep-steps files, we then want to extract the sleep episodes. To do this, we have two parameters: MIN_CONSEC_NON_AWAKE and MAX_CONSEC_AWAKE.\n",
    "\n",
    "MIN_CONSEC_NON_AWAKE is the number of consecutive minutes that a student has to be asleep/restless for an episode to be recognized, and MAX_CONSEC_AWAKE is the number of consecutive awake minutes that have to be recognized for the termination of an episode. Any timepoint where steps are positive is considered awake. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the number of minutes that separates two datetimes\n",
    "def diff_min(dt1,dt2):\n",
    "    \n",
    "    DATE_FORMAT = '%Y-%m-%d %H:%M:%S'\n",
    "    \n",
    "    td = datetime.strptime(dt1, DATE_FORMAT) - datetime.strptime(dt2, DATE_FORMAT)\n",
    "    return int(td.total_seconds() / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_CONSEC_NON_AWAKE = 20\n",
    "MAX_CONSEC_AWAKE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSubjectSleepEpisodes(phase, \n",
    "                            filename,\n",
    "                            min_consec_non_awake = MIN_CONSEC_NON_AWAKE,\n",
    "                            max_consec_awake = MAX_CONSEC_AWAKE):\n",
    "        \n",
    "    path = getPath(phase)\n",
    "\n",
    "    COMBINED_DIR = os.path.join(path, 'sleep_steps_data/')\n",
    "    EPISODES_DIR = os.path.join(path, 'sleep_episodes/')\n",
    "    \n",
    "    # Read combined data\n",
    "    filename = os.path.join(COMBINED_DIR, filename)\n",
    "    combined_df = pd.read_csv(filename, index_col=0)\n",
    "    \n",
    "    # Define fields\n",
    "    columns = ['start_time', 'end_time', 'length', 'time_asleep', 'time_restless', 'time_awake']\n",
    "    \n",
    "    # Make dictionary\n",
    "    episode_dict = {} # start_time -> ['end_time', 'length', 'time_asleep', 'time_restless', 'time_awake']\n",
    "    \n",
    "    # tracks the last time point the subject was awake\n",
    "    last_awake = combined_df.index[0]\n",
    "    \n",
    "    # used for tracking when in or not in and episode\n",
    "    consec_non_awake = 0\n",
    "    consec_awake = 0\n",
    "    on_episode = False\n",
    "    start_index = None\n",
    "\n",
    "    \n",
    "    # iterate through the subject's combined dataframe\n",
    "    for index, row in combined_df.iterrows():\n",
    "        sleep = row['sleep_value']\n",
    "\n",
    "        # update counts\n",
    "        if math.isnan(sleep) or sleep == 3 or sleep == 0: # 3 = awake, 0 = missing in lac1\n",
    "            consec_awake += 1\n",
    "            consec_non_awake = 0\n",
    "            last_awake = index\n",
    "        elif sleep == 1: # 1 = asleep\n",
    "            consec_awake = 0\n",
    "            consec_non_awake += 1\n",
    "        elif sleep == 2: # 2 = restless\n",
    "            consec_awake = 0\n",
    "            consec_non_awake += 1\n",
    "        else:\n",
    "            raise Exception('sleep value is not NaN, 1, 2, or 3')\n",
    "\n",
    "        # update episode status\n",
    "        # starting new episode\n",
    "        if not on_episode and consec_non_awake >= min_consec_non_awake:\n",
    "            on_episode = True\n",
    "            start_index = last_awake\n",
    "            start_loc = combined_df.index.get_loc(index)\n",
    "        # ending episode\n",
    "        elif on_episode and consec_awake >= max_consec_awake:\n",
    "            index_loc = combined_df.index.get_loc(index)\n",
    "            end_index = combined_df.index[index_loc-max_consec_awake+1]\n",
    "            length = diff_min(end_index,start_index)\n",
    "            temp_df = combined_df.iloc[start_loc:index_loc]\n",
    "            time_awake = len(temp_df[temp_df['sleep_value']==3])\n",
    "            time_restless = len(temp_df[temp_df['sleep_value']==2])\n",
    "            time_asleep = length - time_restless - time_awake\n",
    "            episode_dict[start_index] = [end_index, length, time_asleep, time_restless, time_awake]\n",
    "            start_index = index\n",
    "            on_episode = False\n",
    "\n",
    "    # Make dataframe from dictionary\n",
    "    episode_df = pd.DataFrame.from_dict(episode_dict, orient='index', columns=columns[1:])\n",
    "    episode_df.index.name = columns[0]\n",
    "    \n",
    "    return episode_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the main episode date for given time\n",
    "def getWindow(time):\n",
    "    if time.hour < 12:\n",
    "        time = time - timedelta(days=1)\n",
    "    return time.date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeAllEpisodesForParams(phase,\n",
    "                                min_consec_non_awake, \n",
    "                                max_consec_awake):\n",
    "\n",
    "    path = getPath(phase)\n",
    "\n",
    "    COMBINED_DIR = os.path.join(path, 'sleep_steps_data/')\n",
    "    EPISODES_DIR = os.path.join(path, 'sleep_episodes/')    \n",
    "    \n",
    "    \n",
    "    directory = str(min_consec_non_awake) +'_' + str(max_consec_awake) + '/'\n",
    "    directory = os.path.join(EPISODES_DIR, directory)\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(directory)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "    for src in tqdm(os.listdir(COMBINED_DIR)):\n",
    "\n",
    "        \n",
    "\n",
    "        dest = 'EPI_' + src.split('.')[0] + '_' + \\\n",
    "                    str(min_consec_non_awake) + '_' + \\\n",
    "                    str(max_consec_awake) + '.csv'\n",
    "        \n",
    "        dest = os.path.join(directory,dest)\n",
    "        \n",
    "        # if not os.path.exists(dest):    \n",
    "        df = getSubjectSleepEpisodes(\n",
    "                 phase,\n",
    "                 src,\n",
    "                 min_consec_non_awake,\n",
    "                 max_consec_awake)\n",
    "        df.to_csv(dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computeAllEpisodesForParams('lac1',\n",
    "#                             MIN_CONSEC_NON_AWAKE,\n",
    "#                             MAX_CONSEC_AWAKE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computeAllEpisodesForParams('lac2',\n",
    "#                             MIN_CONSEC_NON_AWAKE,\n",
    "#                             MAX_CONSEC_AWAKE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've extracted the sleep episodes (which are in the sleep_episodes/ folder under a subdirectory titled \"MIN_CONSEC_NON_AWAKE\"_\"MAX_CONSEC_AWAKE\"), we then have to compute the sleep features of interest.\n",
    "\n",
    "To do so, we need to convert the bedtime and waketime into minutes after a given zero (e.g. minutes after 6 pm) since time is modulo 24 hr. For bedtime, students generally go to bed after 6 pm, and for waketime, students generally wake up after 4 am (these numbers were not chosen formally). Thus, we set BED_ZERO = 18 (i.e. 6 pm), and WAKE_ZERO = 4 (i.e. 4 am), and convert bedtime and waketime to the number of minutes after these respective zeros.\n",
    "\n",
    "Additionally, we identified the main sleep episode of Day n as the longest sleep episode which started between noon of Day n and noon of Day (n+1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BED_ZERO = 18\n",
    "WAKE_ZERO = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeToMin(time, zero_hour):\n",
    "    \n",
    "    hour = time.hour\n",
    "    minute = time.minute\n",
    "    \n",
    "    if hour < zero_hour:\n",
    "        hour += 24\n",
    "        \n",
    "    return (hour-zero_hour)*60 + minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEpisodeData(phase,\n",
    "                   filename): # ex: 'PID001.csv'\n",
    "    \n",
    "    DATE_FORMAT = '%Y-%m-%d %H:%M:%S'\n",
    "    \n",
    "    path = getPath(phase)\n",
    "    \n",
    "    EPISODES_DIR = os.path.join(path, 'sleep_episodes/20_5/')\n",
    "    file = os.path.join(EPISODES_DIR, 'EPI_'+ filename.split('.')[0] + '_20_5.csv')\n",
    "\n",
    "    df = pd.read_csv(file, header=0)\n",
    "    \n",
    "    df['start_time'] = df['start_time'].apply(lambda x: datetime.strptime(x,DATE_FORMAT))\n",
    "    df['end_time'] = df['end_time'].apply(lambda x: datetime.strptime(x,DATE_FORMAT))\n",
    "    \n",
    "    # define a main sleep episode as the longest sleep episode\n",
    "    # in sleep window\n",
    "    df['subject_id'] = filename.split('.')[0]\n",
    "    df['main_episode_of'] = df['start_time'].apply(lambda x: getWindow(x))\n",
    "    df = df.sort_values(by='length', ascending=False)\n",
    "    df = df.sort_values(by='main_episode_of')    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMainEpisodeData(phase, filename):\n",
    "    \n",
    "    df = getEpisodeData(phase, filename)\n",
    "    df = df.sort_values(by='length', ascending=False)\n",
    "    df = df.drop_duplicates(subset='main_episode_of',keep='first')\n",
    "    df = df.sort_values(by='main_episode_of') \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we compute various sleep features of interest. \n",
    "\n",
    "MSSD refers to mean successive squared difference. This is a measure of variability that also takes into account the temporal nature of the data. For instance, the MSSD of [3,4,10] is ((4-3)^2 + (10-4)^2)/2 = 37/2\n",
    "\n",
    "Not all of these features are used in this SLEEP Poster, but are included in the event of further analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMainEpisodeMSSD(main_episode_df):\n",
    "    \n",
    "    main_episode_df = main_episode_df.sort_values(by='main_episode_of')\n",
    "    \n",
    "    main_episode_df['bedtime'] = main_episode_df['start_time'].apply(lambda x: timeToMin(x,BED_ZERO))\n",
    "    main_episode_df['waketime'] = main_episode_df['end_time'].apply(lambda x: timeToMin(x,WAKE_ZERO))\n",
    "    main_episode_df['midpoint_sleep'] = (main_episode_df['waketime'] + main_episode_df['bedtime']) / 2.0\n",
    "\n",
    "    \n",
    "    count = 0\n",
    "    bt_total = []\n",
    "    wt_total = []\n",
    "    mp_total = []\n",
    "    \n",
    "    for i, idx1 in enumerate(main_episode_df.index):\n",
    "        row1 = main_episode_df.loc[idx1]\n",
    "        \n",
    "        if i < len(main_episode_df.index)-1:\n",
    "            idx2 = main_episode_df.index[i+1]\n",
    "            row2 = main_episode_df.loc[idx2]\n",
    "        else:\n",
    "            row2 = None\n",
    "        \n",
    "        if row2 is not None:\n",
    "            count += 1\n",
    "            bt_total.append((row2['bedtime']-row1['bedtime'])**2)\n",
    "            wt_total.append((row2['waketime']-row1['waketime'])**2)\n",
    "            mp_total.append((row2['midpoint_sleep']-row1['midpoint_sleep'])**2)\n",
    "        \n",
    "    \n",
    "    if count == 0:\n",
    "        return np.nan, np.nan, np.nan, np.nan, np.nan, np.nan\n",
    "    \n",
    "    bt_mssd = np.array(bt_total).mean() / (float(count) * 3600)\n",
    "    wt_mssd = np.array(wt_total).mean() / (float(count) * 3600)\n",
    "    mp_mssd = np.array(mp_total).mean() / (float(count) * 3600)\n",
    "        \n",
    "    bt_mssd_median = median(bt_total)\n",
    "    wt_mssd_median = median(wt_total)\n",
    "    mp_mssd_median = median(mp_total)\n",
    "        \n",
    "    return bt_mssd, wt_mssd, mp_mssd, bt_mssd_median, wt_mssd_median, mp_mssd_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_window and end_window are date objects\n",
    "# extracts start to end inclusive\n",
    "def computeSummaryStats(phase, \n",
    "                        filename, # ex: 'PID001.csv'\n",
    "                        start_window, \n",
    "                        end_window):\n",
    "    \n",
    "        \n",
    "        DATE_FORMAT = '%Y-%m-%d %H:%M:%S'\n",
    "        \n",
    "        summary = dict()\n",
    "        \n",
    "        subject_id = filename.split('.')[0]\n",
    "        \n",
    "        summary['subject_id'] = subject_id\n",
    "        \n",
    " \n",
    "        all_df = getEpisodeData(phase, subject_id)\n",
    "        main_df = getMainEpisodeData(phase, subject_id)\n",
    "\n",
    "        start = pd.Timestamp(start_window)\n",
    "        end = pd.Timestamp(end_window)\n",
    "        main_df = main_df[main_df['main_episode_of'].between(start,end)]\n",
    "        \n",
    "        all_df['start_time'] = all_df['start_time'].apply(lambda x: datetime.strptime(str(x),DATE_FORMAT))\n",
    "        all_df['main_episode_of'] = all_df['start_time'].apply(lambda x: getWindow(x))\n",
    "        all_df = all_df[all_df['main_episode_of'].between(start,end)]\n",
    "        \n",
    "        nap_df = all_df[~all_df.start_time.isin(main_df.start_time)]\n",
    "        \n",
    "        summary['num_naps'] = len(nap_df)\n",
    "        summary['avg_nap_length'] = nap_df['length'].mean()\n",
    "        \n",
    "        try:\n",
    "            summary['frac_napped_of_total_sleep'] = nap_df['length'].sum() / all_df['length'].sum()\n",
    "            summary['avg_24_hr_sleep'] = all_df['length'].sum() / len(all_df['main_episode_of'].unique())\n",
    "            summary['frac_sleep_episodes_as_naps'] = len(nap_df) / len(all_df)\n",
    "            \n",
    "        except: # all_df is empty\n",
    "            summary['frac_napped_of_total_sleep'] = np.nan\n",
    "            summary['avg_24_hr_sleep'] = np.nan\n",
    "            summary['frac_sleep_episodes_as_naps'] = np.nan\n",
    "        \n",
    "        summary['frac_nights_with_data'] = len(main_df) / ((end_window-start_window).days + 1)\n",
    " \n",
    "\n",
    "        if len(main_df) == 0:\n",
    "            return None\n",
    "\n",
    "        \n",
    "        main_df['bedtime'] = main_df['start_time'].apply(lambda x: timeToMin(x,BED_ZERO))\n",
    "        main_df['waketime'] = main_df['end_time'].apply(lambda x: timeToMin(x,WAKE_ZERO)) \n",
    "        main_df['midpoint_sleep'] = (main_df['waketime'] + main_df['bedtime']) / 2.0\n",
    "\n",
    "            \n",
    "        main_df['proportion_awake'] = main_df['time_awake'] / main_df['length']\n",
    "        main_df['proportion_restless'] = main_df['time_restless'] / main_df['length']\n",
    "        main_df['weekday'] = main_df['main_episode_of'].apply(lambda x: x.weekday())\n",
    "        \n",
    "        # 4 = friday night, 5 = saturday night\n",
    "        main_df['is_weekend'] = main_df['weekday'].apply(lambda x: x in [4,5])\n",
    "        \n",
    "        # bedtime measures\n",
    "        summary['bedtime'] = main_df['bedtime'].mean()\n",
    "        summary['bedtime_std'] = main_df['bedtime'].std()\n",
    "    \n",
    "        # waketime measures\n",
    "        summary['waketime'] = main_df['waketime'].mean()\n",
    "        \n",
    "        # midpoint sleep measures\n",
    "        summary['midpoint_sleep'] = main_df['midpoint_sleep'].mean()\n",
    "\n",
    "        # weekday measures\n",
    "        try:  \n",
    "            summary['bedtime_weekday'] = main_df.groupby('is_weekend')['bedtime'].mean()[False]        \n",
    "            summary['waketime_weekday'] = main_df.groupby('is_weekend')['waketime'].mean()[False]\n",
    "            summary['midpoint_sleep_weekday'] = main_df.groupby('is_weekend')['midpoint_sleep'].mean()[False]            \n",
    "        except KeyError:\n",
    "            summary['bedtime_weekday'] = np.nan     \n",
    "            summary['waketime_weekday'] = np.nan\n",
    "            summary['midpoint_sleep_weekday'] = np.nan                \n",
    "        \n",
    "        # weekend measures\n",
    "        try:\n",
    "            summary['bedtime_weekend'] = main_df.groupby('is_weekend')['bedtime'].mean()[True]  \n",
    "            summary['waketime_weekend'] = main_df.groupby('is_weekend')['waketime'].mean()[True]      \n",
    "            summary['midpoint_sleep_weekend'] = main_df.groupby('is_weekend')['midpoint_sleep'].mean()[True]      \n",
    "        except KeyError:\n",
    "            summary['bedtime_weekend'] = np.nan\n",
    "            summary['waketime_weekend'] = np.nan\n",
    "            summary['midpoint_sleep_weekend'] = np.nan\n",
    "\n",
    "            \n",
    "        try:\n",
    "            summary['social_jetlag'] = summary['bedtime_weekend'] - summary['bedtime_weekday']\n",
    "        except:\n",
    "            summary['social_jetlag'] = np.nan\n",
    "            \n",
    "        summary['time_in_bed'] = main_df['length'].mean()\n",
    "                \n",
    "        bt_mssd, wt_mssd, mp_mssd, bt_mssd_median, wt_mssd_median, mp_mssd_median = getMainEpisodeMSSD(main_df)\n",
    "        \n",
    "        summary['bedtime_mssd'] = bt_mssd\n",
    "        summary['waketime_mssd'] = wt_mssd\n",
    "        summary['midpoint_sleep_mssd'] = mp_mssd\n",
    "        \n",
    "        summary['bedtime_mssd_median'] = bt_mssd_median\n",
    "        summary['waketime_mssd_median'] = wt_mssd_median\n",
    "        summary['midpoint_sleep_mssd_median'] = mp_mssd_median\n",
    "        \n",
    "        summary['WASO_fraction'] = main_df['proportion_awake'].mean()\n",
    "        summary['restless_fraction'] = main_df['proportion_restless'].mean()\n",
    "        summary['TST'] = main_df['time_asleep'].mean()\n",
    "        summary['TST_std'] = main_df['time_asleep'].std()\n",
    "        \n",
    "        \n",
    "        return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_window and end_window are date objects\n",
    "def computeAllSummaryStats(phase,\n",
    "                           start_window, \n",
    "                           end_window,\n",
    "                           overwrite=False):\n",
    "    \n",
    "    path = getPath(phase)\n",
    "\n",
    "    FEATURES_FOLDER = os.path.join(path, 'computed_features/')\n",
    "    EPISODES_DIR = os.path.join(path, 'sleep_episodes/')\n",
    "    feature_file = str(start_window) + '_' + str(end_window) + '.csv'       \n",
    "    feature_file = os.path.join(FEATURES_FOLDER,feature_file)    \n",
    "   \n",
    "    if os.path.exists(feature_file) and not overwrite:\n",
    "        return 'Already written'\n",
    "        \n",
    "    if phase not in ['uw1_sum', 'uw2_sum']:\n",
    "        ids = os.listdir(os.path.join(path, 'sleep_steps_data/'))\n",
    "    else:\n",
    "        dir_ids = os.listdir(os.path.join(path, 'sleep_episodes/'))\n",
    "        ids = [x.split('_')[1] for x in dir_ids]\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "    with open(feature_file, 'w') as f:\n",
    "    \n",
    "        header = ['subject_id',\n",
    "                  'num_naps',\n",
    "                  'avg_nap_length',\n",
    "                  'frac_napped_of_total_sleep',\n",
    "                  'avg_24_hr_sleep',\n",
    "                  'frac_sleep_episodes_as_naps',\n",
    "                  'frac_nights_with_data',\n",
    "                  'bedtime',\n",
    "                  'waketime',\n",
    "                  'midpoint_sleep',\n",
    "                  'time_in_bed',\n",
    "                  'bedtime_mssd',\n",
    "                  'bedtime_mssd_median',\n",
    "                  'bedtime_std',\n",
    "                  'bedtime_weekend',\n",
    "                  'bedtime_weekday',\n",
    "                  'waketime_mssd',\n",
    "                  'waketime_mssd_median',\n",
    "                  'waketime_weekend',\n",
    "                  'waketime_weekday',\n",
    "                  'midpoint_sleep_mssd',\n",
    "                  'midpoint_sleep_mssd_median',\n",
    "                  'midpoint_sleep_weekend',\n",
    "                  'midpoint_sleep_weekday',\n",
    "                  'WASO_fraction',\n",
    "                  'restless_fraction',\n",
    "                  'social_jetlag',\n",
    "                  'TST',\n",
    "                  'TST_std']\n",
    "        \n",
    "        w = csv.DictWriter(f, header)\n",
    "        w.writeheader()\n",
    "        \n",
    "        for filename in ids:\n",
    "    \n",
    "            summary = computeSummaryStats(phase, \n",
    "                                          filename,\n",
    "                                          start_window, \n",
    "                                          end_window)\n",
    "                \n",
    "            if not summary:\n",
    "                summary = dict()\n",
    "                for val in header:\n",
    "                    summary[val] = np.nan\n",
    "                summary['subject_id'] = filename.split('.')[0]\n",
    "                summary['frac_nights_with_data'] = 0\n",
    "                \n",
    "            w.writerow(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lac1\n",
    "# computeAllSummaryStats('lac1', date(2017,1,16), date(2017,5,15))\n",
    "\n",
    "# lac2\n",
    "# computeAllSummaryStats('lac2', date(2018,1,16), date(2018,5,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given the start and end of the semester, get the week of semester that contains date\n",
    "def getWeek(date, start, end):\n",
    "    \n",
    "    week_index = pd.date_range(start=start,end=end,freq='w')\n",
    "    \n",
    "    start_date = datetime.strptime(start, '%m/%d/%Y').date()\n",
    "    end_date = datetime.strptime(end, '%m/%d/%Y').date()\n",
    "    \n",
    "    if start_date <= date < week_index[0]:\n",
    "        return 0\n",
    "    elif week_index[0] <= date <  week_index[-1]:\n",
    "        for idx in range(len(week_index)-1):\n",
    "            if  week_index[idx] <= date <  week_index[idx+1]:\n",
    "                return idx+1\n",
    "    elif week_index[-1] <= date <= end_date:\n",
    "        return len(week_index)\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllMainEpisodeData(phase):\n",
    "\n",
    "    path = getPath(phase)\n",
    "    ids = os.listdir(os.path.join(path, 'sleep_steps_data/'))\n",
    "\n",
    "    return pd.concat([getMainEpisodeData(phase, filename) for filename in ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brings column values to front in order listed for dataframe\n",
    "def bringToFront(df, col_names):\n",
    "    col_list = list(df.columns)\n",
    "    for col in col_names[::-1]:\n",
    "        col_list.insert(0,col_list.pop(col_list.index(col)))\n",
    "    \n",
    "    return df.reindex(columns=col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSummaryStats(phase,\n",
    "                    start,\n",
    "                    end):\n",
    "\n",
    "    start_window = start\n",
    "    end_window = end\n",
    "    \n",
    "    path = getPath(phase)\n",
    "            \n",
    "    # get entire semester participant data   \n",
    "    filename = str(start_window) + '_' + str(end_window) + '.csv'\n",
    "    filename = os.path.join(path, 'computed_features/', filename)\n",
    "    summary_stats_df = pd.read_csv(filename)\n",
    "    summary_stats_df.set_index('subject_id', inplace=True)\n",
    "    \n",
    "    return summary_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCESD(phase):\n",
    "    path = os.path.join('EMA_data/',\n",
    "                        phase + '_pre_post_ema.csv')\n",
    "    df = pd.read_csv(path, index_col='ID', low_memory=False)\n",
    "    df.index.names = ['subject_id']\n",
    "    df.index = pd.to_numeric(df.index)\n",
    "    df = df[df['postCESD_sum'] != \" \"]\n",
    "    df['postCESD_sum'] = pd.to_numeric(df['postCESD_sum'])\n",
    "    df = df[df['postCESD_sum'] >= 0]\n",
    "    df = df[df['preCESD_sum'] != \" \"]\n",
    "    df['preCESD_sum'] = pd.to_numeric(df['preCESD_sum'])\n",
    "    df = df[df['preCESD_sum'] >= 0]\n",
    "    return df[['preCESD_sum', 'postCESD_sum']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: X = [pre, predictor], y = [post]\n",
    "# Output: coefficient, p-value for predictor\n",
    "def getOLSResult(X,y,predictor):\n",
    "    \n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    model = sm.OLS(y, X)\n",
    "    results = model.fit()\n",
    "    \n",
    "    return results.params[predictor], results.pvalues[predictor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all predictors of interest, GPA features, no nan rows,\n",
    "# and participants with >=20% fraction of nights data \n",
    "def getRegDF(phase, start, end, predictors, control=None, thresh=0.2):\n",
    "        \n",
    "        # compute summary statistics\n",
    "        computeAllSummaryStats(phase, start, end, overwrite=True) # ADD overwrite=True\n",
    "        stats_df = getSummaryStats(phase, start, end)\n",
    "        \n",
    "        # filter by completeness threshold\n",
    "        # print('Fitbit (no thresh):', len(stats_df), 'participants')\n",
    "        stats_df = stats_df[stats_df['frac_nights_with_data'] >= thresh]\n",
    "        # print('Fitbit (thresh):', len(stats_df), 'participants')\n",
    "\n",
    "        cesd_df = getCESD(phase)\n",
    "        \n",
    "        # combine summary statistics with cesd data\n",
    "        combined_df = stats_df.merge(cesd_df, on='subject_id', how='outer')\n",
    "\n",
    "        # choose only columns of variables of interest\n",
    "        columns = predictors + ['preCESD_sum', 'postCESD_sum'] + ['frac_nights_with_data']\n",
    "                \n",
    "        if control:\n",
    "            columns += [control]        \n",
    "        \n",
    "        combined_df = combined_df[columns].dropna()\n",
    "        \n",
    "        return combined_df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feb 7-28, 2018, thresh=0.2, 160 participants, p = .034\n",
    "def generateBins(num_weeks):\n",
    "    # predictors to test\n",
    "    predictors = ['TST',\n",
    "                  'midpoint_sleep',\n",
    "                  'midpoint_sleep_mssd']\n",
    "\n",
    "    threshold = 0.2\n",
    "    \n",
    "    lac2_semester_start = date(2018,1,17)\n",
    "    lac1_semester_start = date(2017,1,18)\n",
    "\n",
    "    if not os.path.exists(str(num_weeks)+'_week_bins/'):\n",
    "        os.makedirs(str(num_weeks)+'_week_bins/')\n",
    "    \n",
    "    for week in tqdm(range(1,18-num_weeks)):\n",
    "        days_from_start = week*7\n",
    "\n",
    "        dfs = []\n",
    "        for phase in ['lac1', 'lac2']:\n",
    "            if phase == 'lac2': # LAC2 Spring Break: Mar 12-16, 2018\n",
    "                start = lac2_semester_start + timedelta(days=days_from_start)\n",
    "            elif phase == 'lac1': # LAC1 Spring Break: Mar 13-17, 2017\n",
    "                start = lac1_semester_start + timedelta(days=days_from_start)\n",
    "\n",
    "            end = start + timedelta(days=num_weeks*7)\n",
    "\n",
    "\n",
    "            df = getRegDF(phase, start, end, predictors, thresh=threshold)\n",
    "            df['cohort'] = phase\n",
    "            dfs.append(df)\n",
    "        \n",
    "\n",
    "        filepath = str(num_weeks)+'_week_bins/'+str(week)+'_'+str(week+num_weeks)+'.csv'\n",
    "        lac_reg_dfs = pd.concat(dfs)\n",
    "        lac_reg_dfs = pd.concat(dfs).to_csv(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generateBins(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2018, 3, 7)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "week = 7\n",
    "days_from_start = week*7\n",
    "start = date(2018,1,17) + timedelta(days=days_from_start)\n",
    "start\n",
    "\n",
    "# SPRING BREAK IS BETWEEN WEEKS 7-8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
